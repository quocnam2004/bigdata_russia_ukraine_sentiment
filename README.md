
# ğŸ§  Big Data Sentiment Analysis â€“ Russia vs Ukraine Twitter

## ğŸ“¥ Táº£i Dataset (Báº®T BUá»˜C)

**Dataset KHÃ”NG cÃ³ sáºµn trong source code!** Báº¡n cáº§n táº£i tá»« Kaggle:

1. **Download tá»« Kaggle:**
   - Link: https://www.kaggle.com/datasets/bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows
   - Size: ~10GB (292 files CSV)
   - ÄÄƒng nháº­p Kaggle â†’ Download â†’ Giáº£i nÃ©n

2. **Upload lÃªn HDFS:**
   ```powershell
   # Táº¡o thÆ° má»¥c trÃªn HDFS
   hdfs dfs -mkdir -p /data/raw /data/processed /data/results
   
   # Upload táº¥t cáº£ file CSV vÃ o HDFS (thay Ä‘Æ°á»ng dáº«n thá»±c táº¿)
   hdfs dfs -put "C:\Downloads\ukraine-dataset\*.csv" /data/raw/
   
   # Kiá»ƒm tra Ä‘Ã£ upload thÃ nh cÃ´ng
   hdfs dfs -ls /data/raw
   hdfs dfs -du -h /data/raw
   ```

3. **LÆ°u Ã½:**
   - ThÆ° má»¥c `data/raw/` local chá»‰ Ä‘á»ƒ tham kháº£o cáº¥u trÃºc, KHÃ”NG chá»©a data tháº­t
   - Data tháº­t pháº£i náº±m trÃªn HDFS má»›i cháº¡y Ä‘Æ°á»£c
   - Máº¥t ~10-30 phÃºt Ä‘á»ƒ upload tÃ¹y tá»‘c Ä‘á»™ máº¡ng

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c
```
bigdata_russia_ukraine_sentiment/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Dá»¯ liá»‡u gá»‘c (CSV/JSON tá»« Kaggle)
â”‚   â”œâ”€â”€ processed/          # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”‚   â””â”€â”€ results/            # Káº¿t quáº£ phÃ¢n tÃ­ch & biá»ƒu Ä‘á»“
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ etl_preprocess.py   # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (ETL)
â”‚   â”œâ”€â”€ sentiment_model.py  # PhÃ¢n loáº¡i cáº£m xÃºc (Spark ML hoáº·c rule-based)
â”‚   â”œâ”€â”€ trend_analysis.py   # PhÃ¢n tÃ­ch xu hÆ°á»›ng & thá»‘ng kÃª
â”‚
â””â”€â”€ README.md
```

## âš™ï¸ Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng
- **Hadoop**: 3.3.6 (Ä‘Ã£ cÃ i winutils.exe trong `bin/`)
- **Spark**: 3.1.1
- **Python**: >= 3.10
- **PySpark**: 3.1.2

ThÃªm vÃ o PATH:
```powershell
setx HADOOP_HOME "C:\hadoop-3.3.6"
setx SPARK_HOME "C:\spark-3.1.1-bin-hadoop2.7"
setx PATH "%HADOOP_HOME%\bin;%SPARK_HOME%\bin;%PATH%"
```

## ğŸš€ HÆ°á»›ng dáº«n cháº¡y dá»± Ã¡n

### ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng
- Hadoop HDFS 3.3.6+
- Apache Spark 3.1.1+
- Python 3.10+ vá»›i PySpark
- RAM: Tá»‘i thiá»ƒu 8GB (khuyáº¿n nghá»‹ 16GB)

---

## ğŸ”€ Chá»n trÆ°á»ng há»£p cá»§a báº¡n

### âš ï¸ TRÆ¯á»œNG Há»¢P 1: ChÆ°a cÃ³ dá»¯ liá»‡u trÃªn HDFS (Láº§n Ä‘áº§u cháº¡y)

**BÆ°á»›c 1: Táº£i dataset tá»« Kaggle**
```powershell
# Truy cáº­p vÃ  download: https://www.kaggle.com/datasets/bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows
# Giáº£i nÃ©n file zip vÃ o thÆ° má»¥c táº¡m (vÃ­ dá»¥: C:\Downloads\ukraine-dataset\)
```

**BÆ°á»›c 2: Khá»Ÿi Ä‘á»™ng HDFS**
```powershell
jps  # Kiá»ƒm tra HDFS
start-dfs.cmd  # Náº¿u chÆ°a cháº¡y

# Kiá»ƒm tra HDFS Web UI táº¡i: http://localhost:9870
```

**BÆ°á»›c 3: Táº¡o thÆ° má»¥c vÃ  upload data lÃªn HDFS**
```powershell
# Táº¡o cáº¥u trÃºc thÆ° má»¥c
hdfs dfs -mkdir -p /data/raw /data/processed /data/results

# Upload táº¥t cáº£ file CSV (thay Ä‘Æ°á»ng dáº«n thá»±c táº¿)
hdfs dfs -put "C:\Downloads\ukraine-dataset\*.csv" /data/raw/

# Kiá»ƒm tra (pháº£i tháº¥y 292 files, ~10GB)
hdfs dfs -ls /data/raw
hdfs dfs -du -h /data/raw
```

**BÆ°á»›c 4: Cháº¡y pipeline**
```powershell
# Cháº¡y láº§n lÆ°á»£t tá»«ng bÆ°á»›c
spark-submit src\etl_preprocess.py
spark-submit src\sentiment_model.py
spark-submit src\trend_analysis.py
```

---

### âœ… TRÆ¯á»œNG Há»¢P 2: ÄÃ£ cÃ³ dá»¯ liá»‡u trÃªn HDFS (Cháº¡y láº¡i)

**BÆ°á»›c 1: Kiá»ƒm tra HDFS & Data**
```powershell
# Khá»Ÿi Ä‘á»™ng HDFS (náº¿u chÆ°a cháº¡y)
jps
start-dfs.cmd

# Kiá»ƒm tra HDFS Web UI: http://localhost:9870

# XÃ¡c nháº­n cÃ³ data (pháº£i tháº¥y 292 files)
hdfs dfs -ls /data/raw
```

**BÆ°á»›c 2: XÃ³a káº¿t quáº£ cÅ© (náº¿u cáº§n cháº¡y láº¡i)**
```powershell
hdfs dfs -rm -r /data/processed/clean_tweets
hdfs dfs -rm -r /data/results/sentiment_tweets
```

**BÆ°á»›c 3: Cháº¡y pipeline**
```powershell
spark-submit src\etl_preprocess.py
spark-submit src\sentiment_model.py
spark-submit src\trend_analysis.py
```

---

## ğŸ“Š Xem káº¿t quáº£

**Kiá»ƒm tra trÃªn HDFS:**
```powershell
hdfs dfs -ls /data/results/sentiment_tweets
hdfs dfs -count /data/results/sentiment_tweets
```

**Xuáº¥t máº«u ra local:**
```powershell
hdfs dfs -get /data/results/sentiment_tweets/part-00000*.parquet data\results\
```

**Biá»ƒu Ä‘á»“:** File `sentiment_overview.png` trong thÆ° má»¥c hiá»‡n táº¡i

---

## ğŸ”§ Xá»­ lÃ½ sá»± cá»‘

**Lá»—i Out of Memory:**
```powershell
spark-submit --driver-memory 6g --executor-memory 6g src\sentiment_model.py
```

**Spark Web UI:** http://localhost:4040 (khi job Ä‘ang cháº¡y)

---

### ğŸ“Š Káº¿t quáº£ cuá»‘i cÃ¹ng

Sau khi hoÃ n thÃ nh, báº¡n sáº½ cÃ³:
```
HDFS:
â”œâ”€â”€ /data/raw/                    # Dá»¯ liá»‡u gá»‘c (~10GB, 57M tweets)
â”œâ”€â”€ /data/processed/clean_tweets  # Dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch
â””â”€â”€ /data/results/sentiment_tweets # Káº¿t quáº£ phÃ¢n tÃ­ch cáº£m xÃºc

Local:
â””â”€â”€ sentiment_overview.png        # Biá»ƒu Ä‘á»“ tá»•ng quan
```

## ğŸ“Š Káº¿t quáº£
- Biá»ƒu Ä‘á»“ cáº£m xÃºc tá»•ng thá»ƒ
- Biá»ƒu Ä‘á»“ biáº¿n Ä‘á»™ng cáº£m xÃºc theo thá»i gian


## ğŸ§© Ghi chÃº
- Dataset lá»›n (~44GB), nÃªn Æ°u tiÃªn cháº¡y local cluster `--master local[*]`.
- CÃ³ thá»ƒ export sample nhá» Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ nháº¹ hÆ¡n.

---
ğŸ§‘â€ğŸ’» Project thá»±c hiá»‡n bá»Ÿi: TRÃ€ QUá»C NAM
